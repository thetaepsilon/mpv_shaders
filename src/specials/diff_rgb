#!/bin/sh
set -eu;

hookpoint="${at:-MAINPRESUB}";
input="${in:-$hookpoint}";
output="${out:-$input}";

# setup block
src_header() {
	cat << EOF

//!HOOK $hookpoint
//!BIND $input
//!SAVE $output
//!WIDTH ${input}.w 3 *
//!HEIGHT ${output}.h
//!COMPONENTS 3

EOF
}





src_loaded_main() {
	cat << EOF

vec3 linearise_input(vec4 v) {
	// XXX: probably need to do something more clever here in future,
	// like actually interpreting sRGB or such properly.
	// not sure if mpv exposes linear channels for non-HDR content though.
	vec3 col = clamp(v.rgb, vec3(0.0), vec3(1.0));
	return pow(col, vec3(2.2));
}

vec4 output_to_display_space(vec3 result) {
	// XXX: again here assuming output display is fixed values...
	// also we may need to in future output in an adjustable colour space for later stages.
	return vec4(pow(result, vec3(1. / 2.2)), 1.0);
}

vec4 loaded_main(int which, vec4 left, vec4 centre, vec4 right) {
	#define L linearise_input
	vec3 result = linear_light_main(which, L(left), L(centre), L(right));
	#undef L
	return output_to_display_space(result);
}

EOF
}




src_linear_main() {
	cat << EOF

/*
// one approximation of human colour perception is the cube root of linear light.
const vec3 perceptual = vec3(1. / 3.);
// ... hence the reverse is naturally cubing.
const vec3 undo_perceptual = vec3(3.);
*/
// ... adjustment to the above using slightly different gamma curve to address "pixel thinning".
const vec3 perceptual = vec3(0.4);
const vec3 undo_perceptual = vec3(2.5);

vec3 proportional_diff(vec3 a, vec3 b) {
	vec3 ldiff = abs(a - b);

	ldiff = clamp(ldiff, vec3(0.0), vec3(0.25));
	return ldiff;
}





// XXX: I copypasta'd this from another shader. need a proper function library already.

vec3 unit_interval(vec3 v) {
	return clamp(v, 0., 1.);
}

vec3 pick(vec3 _a, vec3 left, vec3 centre, vec3 right) {
	vec3 an = unit_interval(-_a);
	vec3 ap = unit_interval(_a);

	vec3 mn = mix(centre, left, an);
	vec3 mp = mix(centre, right, ap);
	vec3 result = mn + mp - centre;

	return result;
}

// end copypasta






vec3 linear_light_main(int _which, vec3 left, vec3 centre, vec3 right) {
	#define S(c) vec3 p_ ## c = pow(c, perceptual)
	S(left);
	S(centre);
	S(right);
	#undef S

	// centre bias the subpixel so left (initially zero) becomes -1.
	int which = _which - 1;

	// this shader is based on a specialised weighting / lerp function between pixels.
	// the individual RGB channels have their positions effectively shifted by nudging this.
	// for instance: BGR pixel ordering, blue comes on the left,
	// so at the right (+x) edge of the virtual pixel it will have further progressed.
	// XXX: allow overriding ordering here...
	//const float T = 1. / 3.;
	ivec3 nudges = ivec3(-1, 0, 1);

	// also nudge the function along depending on which subpixel we're in.
	nudges += ivec3(which);
	vec3 nudges_f = vec3(nudges) * 0.33;

	// debug perceptual blend
	vec3 p_ret = pick(nudges_f, p_left, p_centre, p_right);

	// darken the channels when in lerp phase
	bvec3 are_nonzero = greaterThan(abs(nudges), ivec3(0));
	vec3 modulate = vec3(1.0) - (vec3(are_nonzero) * 0.125);
	p_ret *= modulate;

	// do comparison of current and neighbor pixels in the appropriate direction.
	// for each r, g and b channel,
	// we need to do a three-way select of what is the "neighbour".
	// this is a buggerance enough to do even two-way as it is in GLSL ES,
	// due to lack of component-wise mix(bvec, genvec, genvec).
	// so implement it manually with multiply masks and adds (and hope no NaNs appear).
	// needs to be three-way as then we can naturally have zero difference comparing to itself,
	// so the centre point of each subpixel doesn't lose any luminosity at this step.
	ivec3 nudge_signs = clamp(nudges, -1, 1);
	#define get_contrib(side, index) \
		vec3 contrib_ ## side = side * vec3(equal(nudge_signs, ivec3( index )))
	
	get_contrib(left, -1);
	get_contrib(centre, 0);
	get_contrib(right, 1);
	#undef get_contrib
	vec3 comparison = contrib_left + contrib_right + contrib_centre;

	// custom gamma for comparing differences
	const vec3 diffspace = vec3(0.25);
	vec3 d_comparison = pow(comparison, diffspace);
	vec3 d_centre = pow(centre, diffspace);
	vec3 adiff = proportional_diff(d_centre, d_comparison);
	// tuning of how fast the effect kicks in.
	adiff = pow(adiff, vec3(1.25));


	p_ret = pow(p_ret, undo_perceptual);
	//p_ret *= vec3(1.0) - (abs(diff) * vec3(0.5));
	p_ret *= exp2(vec3(-3.0) * adiff);

	return p_ret;
}

EOF
}





# the hook() function is responsible for somehow loading the three needed pixel values,
# calling the actual colour calculation with them,
# and then using the result as the shader output.
# the precise load mechanism may change later if a more efficient method is discovered.
src_fetch_main() {
	cat << EOF

#define SZ ${input}_size

// rounding helpers defined here as this is only needed for the texture loading for the time being.
vec4 load(vec2 pix) {
	vec2 pos = pix / SZ;
	return ${input}_tex(pos);
}

float nearest_pixel(float value) {
	return floor(value) + 0.5;
}

vec4 hook() {
	// work out nearest pixel in source image along x axis,
	// then load that as well as the two neighbours.
	// y doesn't have to be touched, as the image height isn't being changed.
	vec2 current_output_pixel = gl_FragCoord.xy;

	float src_x = nearest_pixel(current_output_pixel.x / 3.0);
	vec2 src_centre = vec2(src_x, current_output_pixel.y);

	vec4 centre = load(src_centre);
	vec4 left = load(src_centre + vec2(-1., 0.));
	vec4 right = load(src_centre + vec2(1., 0.));

	// additionally work out which "subpixel" we are currently located in.
	float which_f = mod(gl_FragCoord.x, 3.0);
	int which = int(which_f);

	return loaded_main(which, left, centre, right);
}

EOF
}




src_header
src_linear_main
src_loaded_main
src_fetch_main


