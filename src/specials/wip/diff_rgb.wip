#!/bin/sh
set -eu;



err() {
	echo "#" "$@" >&2;
}

die() {
	err "$@";
	err "${0}: abort!"
	exit 1;
}



hookpoint="${at:-MAINPRESUB}";
input="${in:-$hookpoint}";
output="${out:-$input}";



# available subpixel orders.
# only two really for the time being.
# it is important that the picked order matches the user's real display,
# if the display is itself either RGB or BGR stripes.
# this _includes_ adjustment if the display is rotated.
# if the orientation at any time ends up with the order going _against_ the display
# (e.g. BGR on an RGB display), the two will cancel out in a disruptive manner.
# in any case, what these must do is set up up nudge offsets as used by linear_light_main() below.
subpixel_order="${subpixel_order:-rgb}";
subpixel_order_rgb() { echo "1, 0, -1"; }
subpixel_order_bgr() { echo "-1, 0, 1"; }
ordering="$("subpixel_order_${subpixel_order}")" || \
	die "unrecognised subpixel ordering: $subpixel_order";



# "crt mode": disables the darkening of the colour channels when it's not their home position.
src_frag_main_crt_mode_enabled() {
	cat << EOF
	// darken the channels when in lerp phase
	bvec3 are_nonzero = greaterThan(abs(nudges), ivec3(0));
	vec3 modulate = vec3(1.0) - (vec3(are_nonzero) * 7. / 64.);
	p_ret *= modulate;
EOF
}
src_frag_main_crt_mode() {
	if test -z "${crt_mode:-}"; then src_frag_main_crt_mode_enabled; fi;
}





# currently hardcoded off during refactoring.
vertical="";





_stretch="3 *"

# setup block
src_header() {
	widthmult="";
	heightmult="";

	if test -z "$vertical"; then {
		widthmult="$_stretch";
	}; else {
		heightmult="$_stretch";
	}; fi;

	cat << EOF

//!HOOK $hookpoint
//!BIND $input
//!SAVE $output
//!WIDTH ${input}.w ${widthmult}
//!HEIGHT ${input}.h ${heightmult}
//!COMPONENTS 3

EOF
}





src_loaded_main() {
	cat << EOF

vec3 linearise_input(vec4 v) {
	// XXX: probably need to do something more clever here in future,
	// like actually interpreting sRGB or such properly.
	// not sure if mpv exposes linear channels for non-HDR content though.
	vec3 col = clamp(v.rgb, vec3(0.0), vec3(1.0));
	return pow(col, vec3(2.2));
}

vec4 output_to_display_space(vec3 result) {
	// XXX: again here assuming output display is fixed values...
	// also we may need to in future output in an adjustable colour space for later stages.
	return vec4(pow(result, vec3(1. / 2.2)), 1.0);
}

vec4 loaded_main(int which, vec4 left, vec4 centre, vec4 right) {
	#define L linearise_input
	vec3 result = linear_light_main(which, L(left), L(centre), L(right));
	#undef L
	return output_to_display_space(result);
}

EOF
}




src_linear_main() {
	cat << EOF

/*
// one approximation of human colour perception is the cube root of linear light.
const vec3 perceptual = vec3(1. / 3.);
// ... hence the reverse is naturally cubing.
const vec3 undo_perceptual = vec3(3.);
*/
// ... adjustment to the above using slightly different gamma curve to address "pixel thinning".
const vec3 perceptual = vec3(0.4);
const vec3 undo_perceptual = vec3(2.5);

// visual error flag colour (read in heavy's voice)
const vec3 bigtroublenow = vec3(1.0, 0.0, 1.0);

vec3 diff_factor(vec3 a, vec3 b) {
	// custom gamma for comparing differences
	const vec3 diffspace = vec3(0.25);
	a = pow(a, diffspace);
	b = pow(b, diffspace);

	/*
	proportional diff by taking the ratio of the smallest value (per-channel)
	to the biggest, yielding a value in the range 0 - 1.
	we do this by dividing the smallest value with the largest
	(the largest divided by itself becomes 1, aka the reference).

	a problem occurs if (again channel-wise independently)
	a and b are zero however (hence their max is also zero).
	dividing by zero yields an unspecified but non-crashing result,
	including NaNs which may poison further calculations with the result.
	furthermore GLSL ES 1.00 lacks mix(bvec, ...),
	so disregarding troublesome values is tricky.
	instead, detect the situation but replace the divide-by-zero with divide-by-something-tiny,
	then use addition of multiply masks later to get rid of the nonsense.
	*/

	const vec3 zero = vec3(0.0);
	// get rid of pesky negatives, those can show up from source video texture a lot.
	// cause isn't quite known, though might be out-of-gamut issues from yuv conversion,
	// coupled with e.g. inprecise DCTs causing the reconstructed result to be out of bounds.
	// if they appeared here they'd screw up the signs of everything on divide.
	a = max(a, zero);
	b = max(b, zero);

	// remember, component-wise
	vec3 lower = min(a, b);
	vec3 _higher = max(a, b);

	// check for those pesky zeroes in the divisor (aka the higher value(s))
	// and remember which channels they're in,
	// then replace them with dummy values so the below division is defined.
	// we will later consult the bvec to know which values can be disregarded.
	bvec3 is_zero = equal(_higher, zero);
	bvec3 is_nonzero = not(is_zero);

	// ensure any zero channel gets set to something that won't cause divide by zero.
	// (vec3 cast of bvec3: true bits become 1.0, so anything zero becomes 1.0 instead)
	vec3 higher_nz = _higher + vec3(is_zero);

	vec3 ratio = lower / higher_nz;

	// ratio of 1.0 means lower == higher, aka zero difference.
	vec3 diff = vec3(1.0) - ratio;

	// in the 0/0 case, we consider that zero difference,
	// so use the inverted (non-zero) mask to disable those components.
	// non-zero channels will be multiplied by 1.0 and be unchanged.
	diff *= vec3(is_nonzero);

	//if (any(lessThan(diff, zero))) return bigtroublenow;

	diff = max(diff, zero);
	// tuning of how fast the effect kicks in.
	//diff = pow(diff, vec3(1.25));

	//vec3 mult = exp2(vec3(-2.5) * diff);
	vec3 mult = vec3(1.0) - (min(diff, vec3(0.8)) * 0.8);

	return mult;
}





// XXX: I copypasta'd this from another shader. need a proper function library already.

vec3 unit_interval(vec3 v) {
	return clamp(v, 0., 1.);
}

vec3 pick(vec3 _a, vec3 left, vec3 centre, vec3 right) {
	vec3 an = unit_interval(-_a);
	vec3 ap = unit_interval(_a);

	vec3 mn = mix(centre, left, an);
	vec3 mp = mix(centre, right, ap);
	vec3 result = mn + mp - centre;

	return result;
}

// end copypasta






const ivec3 initial_nudges = ivec3(${ordering});

vec3 linear_light_main(int _which, vec3 left, vec3 centre, vec3 right) {
	#define S(c) vec3 p_ ## c = pow(c, perceptual)
	S(left);
	S(centre);
	S(right);
	#undef S

	// centre bias the subpixel so left (initially zero) becomes -1.
	int which = _which - 1;

	// this shader is based on a specialised weighting / lerp function between pixels.
	// the individual RGB channels have their positions effectively shifted by nudging this.
	// for instance: BGR pixel ordering, blue comes on the left,
	// so at the right (+x) edge of the virtual pixel it will have further progressed.
	// XXX: allow overriding ordering here...
	//const float T = 1. / 3.;
	ivec3 nudges = initial_nudges;

	// also nudge the function along depending on which subpixel we're in.
	nudges += ivec3(which);
	vec3 nudges_f = vec3(nudges) * 0.33;

	// debug perceptual blend
	vec3 p_ret = pick(nudges_f, p_left, p_centre, p_right);
EOF
	src_frag_main_crt_mode;
cat << EOF

	// do comparison of current and neighbor pixels in the appropriate direction.
	// for each r, g and b channel,
	// we need to do a three-way select of what is the "neighbour".
	// this is a buggerance enough to do even two-way as it is in GLSL ES,
	// due to lack of component-wise mix(bvec, genvec, genvec).
	// so implement it manually with multiply masks and adds (and hope no NaNs appear).
	// needs to be three-way as then we can naturally have zero difference comparing to itself,
	// so the centre point of each subpixel doesn't lose any luminosity at this step.
	ivec3 nudge_signs = clamp(nudges, -1, 1);
	#define get_contrib(side, index) \
		vec3 contrib_ ## side = side * vec3(equal(nudge_signs, ivec3( index )))
	
	get_contrib(left, -1);
	get_contrib(centre, 0);
	get_contrib(right, 1);
	#undef get_contrib
	vec3 comparison = contrib_left + contrib_right + contrib_centre;

	vec3 diff_mult = diff_factor(centre, comparison);

	p_ret = pow(p_ret, undo_perceptual);
	p_ret *= diff_mult;

	return p_ret;
}

EOF
}





# the hook() function is responsible for somehow loading the three needed pixel values,
# calling the actual colour calculation with them,
# and then using the result as the shader output.
# the precise load mechanism may change later if a more efficient method is discovered.
src_fetch_main() {
	# swizzle masks for converting to/from operation axes
	op_swizzle="";
	undo_swizzle="";

	# the step vector values used to determine sampling offsets.
	step="1.0, 0.0";

	cat << EOF

#define SZ ${input}_size

// rounding helpers defined here as this is only needed for the texture loading for the time being.
vec4 load(vec2 pix) {
	vec2 pos = pix / SZ;
	return ${input}_tex(pos);
}

float nearest_pixel(float value) {
	return floor(value) + 0.5;
}

vec2 step_v = vec2(${step});

// go from x, y to major, minor axis.
// major is the direction of operation and is /usually/ X,
// in which case this function is a no-op from a traditional x-y vector.
// TODO: enable overriding.
vec2 to_op_axes(vec2 xy) {
	return xy${op_swizzle};
}
// and the inverse.
vec2 from_op_axes(vec2 st) {
	return st${undo_swizzle};
}

vec2 steps(float steps_f) {
	return step_v * vec2(steps_f);
}

vec4 hook() {
	// work out nearest pixel in source image along x axis,
	// then load that as well as the two neighbours.
	// y doesn't have to be touched, as the image height isn't being changed.
	vec2 current_output_pixel = gl_FragCoord.xy;

	vec2 op_current = to_op_axes(current_output_pixel);

	float op_src_major_axis = nearest_pixel(op_current.s / 3.0);
	vec2 op_src_centre = vec2(op_src_major_axis, op_current.t);
	vec2 src_centre = from_op_axes(op_src_centre);

	vec4 centre = load(src_centre);
	vec4 left = load(src_centre + steps(-1.0));
	vec4 right = load(src_centre + steps(1.0));

	// additionally work out which "subpixel" we are currently located in.
	float which_f = mod(op_current.s, 3.0);
	int which = int(which_f);

	return loaded_main(which, left, centre, right);
}

EOF
}




src_header
src_linear_main
src_loaded_main
src_fetch_main


